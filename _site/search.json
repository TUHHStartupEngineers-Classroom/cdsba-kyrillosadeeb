[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "library(dplyr)\n\nrandom_vars &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/random_vars.rds\")\n\n\n\n\nageExpectedValue &lt;- summarise(random_vars, mean = mean(age))\nprint(ageExpectedValue)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1  33.5\n\nageVariance &lt;- var(random_vars[,1])\nprint(ageVariance)\n\n#&gt;          age\n#&gt; age 340.6078\n\nageStandardDeviation &lt;- summarise(random_vars, sd = sd(age))\nprint(ageStandardDeviation)\n\n#&gt; # A tibble: 1 × 1\n#&gt;      sd\n#&gt;   &lt;dbl&gt;\n#&gt; 1  18.5\n\n\n\n\n\n\nincomeExpectedValue &lt;- summarise(random_vars, mean = mean(income))\nprint(incomeExpectedValue)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 3511.\n\nincomeVariance &lt;- var(random_vars[,2])\nprint(incomeVariance)\n\n#&gt;         income\n#&gt; income 8625646\n\nincomeStandardDeviation &lt;- summarise(random_vars, sd = sd(income))\nprint(incomeStandardDeviation)\n\n#&gt; # A tibble: 1 × 1\n#&gt;      sd\n#&gt;   &lt;dbl&gt;\n#&gt; 1 2937.\n\n\n\n\n\n\nWell I believe that there’s no sense to compare the standard deviations because simple the income and age aren’t directly related and hence we cannot say that if someone’s age is above the mean with a certain deviation that their income will increase by a certain deviation and vice versa\n\n\n\n\ncov &lt;- cov(random_vars[,1],random_vars[,2])\nprint(cov)\n\n#&gt;       income\n#&gt; age 29700.15\n\ncor &lt;- cor(random_vars[,1],random_vars[,2])\nprint(cor)\n\n#&gt;        income\n#&gt; age 0.5479432\n\n\n\n\n\nCorrelation is easier to interpret because it is bounded with the magnitude showing us how strong or how weak is the relationship and the sign shows us the direction. Meanwhile the covariance is value that doesn’t really tell us much, in terms of the number provided.\n\n\n\n\n\\(E[income \\mid age &gt;= 18]\\)\n\n\ne1 &lt;- summarise(random_vars[random_vars$age&gt;=18,], mean = mean(income))\nprint(e1)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 4464.\n\n\n\n\\(E[income \\mid age \\in [18,65)]\\)\n\n\ne2 &lt;- summarise(random_vars[random_vars$age &gt;= 18 & random_vars$age&lt;65,], mean = mean(income))\nprint(e2)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 4686.\n\n\n\n\\(E[income \\mid age &gt;= 65]\\)\n\n\ne3 &lt;- summarise(random_vars[random_vars$age &gt;= 65,], mean = mean(income))\nprint(e3)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 1777."
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "Plotting a Spurious Correlation\nThis is a plot of one of the spurious correlations that relates US spending on science, space and technology to Suicides by hanging, strangulation and suffocation. I couldn’t find the data as a data set so I generated similar data to plot the graphs.\n\nlibrary(tidyverse)\nlibrary(patchwork)\n\n#Number of entries \nn &lt;- 20\n\n# Create Hanging Suicides Data\nhanging_suicide &lt;- tibble(\n  y = rnorm(n, exp(seq(from = 2, to = 4, length.out = n)), sd = 1),\n  x = seq(from = 1999, to = 2009, length.out = n)\n)\n\n#Creating US spending data\nUS_spending &lt;- tibble(\n  y1 = rnorm(n, exp(seq(from = 2, to = 4, length.out = n)), sd = 3),\n  x1 = seq(from = 1999, to = 2009, length.out = n)\n)\n\np1 &lt;- ggplot(hanging_suicide, aes(x = x, y = y)) +\n  xlab(\"Years\")+\n  ylab(\"No. of suicides (x100)\")+\n  geom_point(size = 3, alpha = 0.8) +\n  geom_line(linewidth = 1, color = 'red')\n  \np2 &lt;- ggplot(US_spending, aes(x = x1, y = y1)) +\n  xlab(\"Years\")+\n  ylab(\"Money Spent (Billions)\")+\n  geom_point(size = 3, alpha = 0.8) +\n  geom_line(linewidth = 1, color = 'blue')\n\np1 + p2"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "In the parking spots example we had the parking spots as treatment variables, the stores as observation units and the sales as an outcome also taking into consideration the location as a confounder.\n\n# Load packages\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n\n\n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(ggplot2)\n\n#Create DAG model\nparking_model &lt;- dagify(\n  S ~ L,\n  A ~ P,\n  B ~ P,\n  C ~ P,\n  D ~ P,\n  S ~ A,\n  S ~ B,\n  S ~ C,\n  S ~ D,\n  coords = list(x = c(L = 7,P = 1,A = 3,B = 3,C = 3,D = 3,S = 7),\n                y = c(L = 1,P = 0,A = 1,B = 0.5,C = -0.5,D = -1,S = 0)),\n  labels = list(L=\"location\",\n                P = \"parking spots\",\n                A = \"Store A\",\n                B = \"Store B\",\n                C = \"Store C\",\n                D = \"Store D\",\n                S = \"Sales\")\n)\n\n#Plot DAG model\nggdag(parking_model) +\n  theme_dag()+\n  geom_dag_node(color = \"red\")+\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ lubridate 1.9.3     ✔ tibble    3.2.1\n#&gt; ✔ purrr     1.0.2     ✔ tidyr     1.3.0\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncustomer_sat &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/customer_sat.rds\")\nhead(customer_sat)\n\n\n\n  \n\n\nlm_first &lt;- lm(satisfaction ~ follow_ups, data = customer_sat)\nsummary(lm_first)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\nlm_second &lt;- lm(satisfaction ~ follow_ups + subscription, data = customer_sat)\nsummary(lm_second)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n\n\nOne of the possible reasons for having a negative estimate in the first regression and then a positive one in the second could be due to the nature of the follow-up calls. So when we speak about follow-ups in general its usually a problem and at lower subscription levels the solution could be to upgrade their subscription which is more expensive and hence the customer isn’t satisfied with the outcome, it could also be a bug or a complain which applies to all subscription levels but when you factor in the subscription level the nature of the calls could be about an upgrade or an inquiry about a feature that gets resolved and the customer is satisfied.\nAnother explanation that appears later when plotting the data is that when we don’t factor the subscription levels it shows that overall the more the follow-ups the less the satisfaction but when you factor the subscription you find that every subscription level has its own range of satisfaction which when isolated shows us an increase in satisfaction as the increase of follow-ups.\n\n\n\n\nno_sub_sat &lt;- ggplot(customer_sat, aes(x = follow_ups, y = satisfaction)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nsub_sat &lt;- ggplot(customer_sat, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nno_sub_sat\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsub_sat\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nabtest &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/abtest_online.rds\")\n\ncompare &lt;- \n  ggplot(abtest, \n         aes(x = chatbot, \n             y = purchase_amount, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = NULL, y = \"Purchase Amount\", title = \"Difference in Purchase Amount\")\n\ncompare\n\n\n\n\n\n\n\n\nAs we can see in the plot the covariates are not balanced.\n\n\n\n\nlm_sales &lt;- lm(purchase_amount ~ chatbot, data = abtest)\nsummary(lm_sales)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = abtest)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n\nThe coefficient is a negative number telling us that the chatbots are affecting the sales in a negative way decreasing the sales and not increasing them.\n\n\n\n\nlm_sales_plus_mob &lt;- lm(purchase_amount ~ chatbot*mobile_device, data = abtest)\nsummary(lm_sales_plus_mob)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = abtest)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n\n\n\n\n\nglm_sales &lt;- glm(purchase ~ chatbot, family = binomial(link = 'logit'), abtest)\nsummary(glm_sales)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = abtest)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\nIn logistic regression we don’t just look at the coefficient but its exponent and that tells us the “odds ratio” which is the ratio of the probability of an event happening divided by the probability of the non event.\nSince the coefficient here is a negative number hence the odds ratio is less than one and that tells us that the event will most likely not happen.\nIn our case the event is the purchase and so the regression tells us that having the chatbot means that the probability of the customer making a purchase is less than that when the customer doesn’t have a chat bot. This means that the chat bot is negatively affecting the number of purchases and hence decreasing the sales."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "\\(P(T \\cap S) = P(T \\mid S) * P(S) = 0.2 *0.3 = 0.06\\)\n\\(P(T \\cap \\overline{S}) = P(T \\mid \\overline{S}) * P(\\overline{S}) = 0.6 *0.7 = 0.42\\)\n\\(P(\\overline{T} \\cap S) = P(\\overline{T} \\mid S) * P(S) = 0.8 *0.3 = 0.24\\)\n\\(P(\\overline{T} \\cap \\overline{S}) = P(\\overline{T} \\mid \\overline{S}) * P(\\overline{S}) = 0.7 *0.4 = 0.28\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "3.1 Header 2",
    "text": "3.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncar_prices &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/car_prices.rds\")\n\ndim(car_prices)\n\n#&gt; [1] 181  22\n\n\nThe dimensions of the data set is 188 rows and 22 coloumns\n\n\n\n\nglimpse(car_prices)\n\n#&gt; Rows: 181\n#&gt; Columns: 22\n#&gt; $ aspiration       &lt;chr&gt; \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std…\n#&gt; $ doornumber       &lt;chr&gt; \"two\", \"two\", \"two\", \"four\", \"four\", \"two\", \"four\", \"…\n#&gt; $ carbody          &lt;chr&gt; \"convertible\", \"convertible\", \"hatchback\", \"sedan\", \"…\n#&gt; $ drivewheel       &lt;chr&gt; \"rwd\", \"rwd\", \"rwd\", \"fwd\", \"4wd\", \"fwd\", \"fwd\", \"fwd…\n#&gt; $ enginelocation   &lt;chr&gt; \"front\", \"front\", \"front\", \"front\", \"front\", \"front\",…\n#&gt; $ wheelbase        &lt;dbl&gt; 88.6, 88.6, 94.5, 99.8, 99.4, 99.8, 105.8, 105.8, 105…\n#&gt; $ carlength        &lt;dbl&gt; 168.8, 168.8, 171.2, 176.6, 176.6, 177.3, 192.7, 192.…\n#&gt; $ carwidth         &lt;dbl&gt; 64.1, 64.1, 65.5, 66.2, 66.4, 66.3, 71.4, 71.4, 71.4,…\n#&gt; $ carheight        &lt;dbl&gt; 48.8, 48.8, 52.4, 54.3, 54.3, 53.1, 55.7, 55.7, 55.9,…\n#&gt; $ curbweight       &lt;dbl&gt; 2548, 2548, 2823, 2337, 2824, 2507, 2844, 2954, 3086,…\n#&gt; $ enginetype       &lt;chr&gt; \"dohc\", \"dohc\", \"ohcv\", \"ohc\", \"ohc\", \"ohc\", \"ohc\", \"…\n#&gt; $ cylindernumber   &lt;chr&gt; \"four\", \"four\", \"six\", \"four\", \"five\", \"five\", \"five\"…\n#&gt; $ enginesize       &lt;dbl&gt; 130, 130, 152, 109, 136, 136, 136, 136, 131, 131, 108…\n#&gt; $ fuelsystem       &lt;chr&gt; \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi…\n#&gt; $ boreratio        &lt;dbl&gt; 3.47, 3.47, 2.68, 3.19, 3.19, 3.19, 3.19, 3.19, 3.13,…\n#&gt; $ stroke           &lt;dbl&gt; 2.68, 2.68, 3.47, 3.40, 3.40, 3.40, 3.40, 3.40, 3.40,…\n#&gt; $ compressionratio &lt;dbl&gt; 9.00, 9.00, 9.00, 10.00, 8.00, 8.50, 8.50, 8.50, 8.30…\n#&gt; $ horsepower       &lt;dbl&gt; 111, 111, 154, 102, 115, 110, 110, 110, 140, 160, 101…\n#&gt; $ peakrpm          &lt;dbl&gt; 5000, 5000, 5000, 5500, 5500, 5500, 5500, 5500, 5500,…\n#&gt; $ citympg          &lt;dbl&gt; 21, 21, 19, 24, 18, 19, 19, 19, 17, 16, 23, 23, 21, 2…\n#&gt; $ highwaympg       &lt;dbl&gt; 27, 27, 26, 30, 22, 25, 25, 25, 20, 22, 29, 29, 28, 2…\n#&gt; $ price            &lt;dbl&gt; 13495.00, 16500.00, 16500.00, 13950.00, 17450.00, 152…\n\n\nHere I used glimpse instead of head to help me see all the coloums and their data types. Strings are recorded as chars and numbers are double allowing decimal values.\n\n\n\n\nlm_all &lt;- lm(price ~ ., data = car_prices)\nsummary(lm_all)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the summary we could see that the main factors relevant are:\n\nenginetype (mostly)\neniginesize\nstroke\npeakrpm\n\n\n\n\n\nlm_top &lt;- lm(price ~ enginetype +\n                     enginesize +\n                     stroke +\n                     peakrpm,\n                     data = car_prices)\nsummary(lm_top)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ enginetype + enginesize + stroke + peakrpm, \n#&gt;     data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -14872.1  -1453.3   -410.3   1563.4  10058.4 \n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)     -1.618e+04  4.220e+03  -3.834 0.000177 ***\n#&gt; enginetypedohcv  1.280e+03  3.135e+03   0.408 0.683638    \n#&gt; enginetypel      3.842e+03  1.480e+03   2.596 0.010256 *  \n#&gt; enginetypeohc    2.550e+03  9.641e+02   2.645 0.008925 ** \n#&gt; enginetypeohcf   6.534e+02  1.283e+03   0.509 0.611213    \n#&gt; enginetypeohcv  -4.967e+03  1.284e+03  -3.870 0.000154 ***\n#&gt; enginesize       2.145e+02  7.630e+00  28.106  &lt; 2e-16 ***\n#&gt; stroke          -5.398e+03  9.088e+02  -5.939 1.55e-08 ***\n#&gt; peakrpm          3.400e+00  5.522e-01   6.158 5.05e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2971 on 172 degrees of freedom\n#&gt; Multiple R-squared:  0.8704, Adjusted R-squared:  0.8644 \n#&gt; F-statistic: 144.4 on 8 and 172 DF,  p-value: &lt; 2.2e-16\n\n\nAs we can see the smallest p-value is the one for engine size and hence im picking it to be my regressor.\n\nmax(car_prices$enginesize)\n\n#&gt; [1] 326\n\nmin(car_prices$enginesize)\n\n#&gt; [1] 61\n\n\nThe regressor I chose is of type double and its values in this data set ranges from 61 to 326.\nIt has a big effect on the price since the p value is very small it denies the null hypothesis and tells that that there is a strong corellation between both factors.\n\nlm_summarised &lt;- lm(price ~ enginesize, data = car_prices)\nconfint(lm_summarised, level = 0.95)\n\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept) -10346.0474 -6898.5441\n#&gt; enginesize     157.1932   182.9353\n\n\nThe estimate is completely positive hence the effect is statistically significant.\n\n\n\n\nnew_car_prices &lt;- mutate(car_prices, seat_heating = TRUE)\nlm_heat &lt;- lm(price ~ ., data = new_car_prices)\nsummary(lm_heat)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = new_car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/01_probability.html#givens",
    "href": "content/01_journal/01_probability.html#givens",
    "title": "Probability Theory",
    "section": "Givens",
    "text": "Givens\n\\(P(B \\mid A) = 0.97\\)\n\\(P(B \\mid \\overline{A}) = 0.01\\)\n\\(P(A) = 0.04\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#solution",
    "href": "content/01_journal/01_probability.html#solution",
    "title": "Probability Theory",
    "section": "",
    "text": "\\(P(T \\cap S) = P(T \\mid S) * P(S) = 0.2 *0.3 = 0.06\\)\n\\(P(T \\cap \\overline{S}) = P(T \\mid \\overline{S}) * P(\\overline{S}) = 0.6 *0.7 = 0.42\\)\n\\(P(\\overline{T} \\cap S) = P(\\overline{T} \\mid S) * P(S) = 0.8 *0.3 = 0.24\\)\n\\(P(\\overline{T} \\cap \\overline{S}) = P(\\overline{T} \\mid \\overline{S}) * P(\\overline{S}) = 0.7 *0.4 = 0.28\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#given",
    "href": "content/01_journal/01_probability.html#given",
    "title": "Probability Theory",
    "section": "",
    "text": "## Solution\n\n\\(P(T \\cap S) = P(T \\mid S) * P(S) = 0.2 *0.3 = 0.06\\)\n\\(P(T \\cap \\overline{S}) = P(T \\mid \\overline{S}) * P(\\overline{S}) = 0.6 *0.7 = 0.42\\)\n\\(P(\\overline{T} \\cap S) = P(\\overline{T} \\mid S) * P(S) = 0.8 *0.3 = 0.24\\)\n\\(P(\\overline{T} \\cap \\overline{S}) = P(\\overline{T} \\mid \\overline{S}) * P(\\overline{S}) = 0.7 *0.4 = 0.28\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#given-1",
    "href": "content/01_journal/01_probability.html#given-1",
    "title": "Probability Theory",
    "section": "Given",
    "text": "Given"
  },
  {
    "objectID": "content/01_journal/01_probability.html#solution-1",
    "href": "content/01_journal/01_probability.html#solution-1",
    "title": "Probability Theory",
    "section": "Solution",
    "text": "Solution\n\nPercentage of customers using all 3 devices:\n\\((Smartphone \\cap Tablet \\cap Computer) = 0.5\\%\\)\nPercentage of customers using at least 2 devices:\n\\((Smartphone \\cap Tablet \\cap Computer) + (Smartphone \\cap Tablet) +(Tablet \\cap Computer) + (Smartphone \\cap Computer)\\)\n\\(= 0.5\\% + 7.3\\% + 3.3\\% + 8.8\\% = 19.9\\%\\)\nPercentage of customers using only 1 device = Percentage of users - Percentage of users using at least 2 devices:\n\\(100\\% - 19.9\\% = 80.1\\%\\)"
  },
  {
    "objectID": "content/01_journal/01_probability.html#solution-2",
    "href": "content/01_journal/01_probability.html#solution-2",
    "title": "Probability Theory",
    "section": "Solution",
    "text": "Solution\n\n\\(P(\\overline{A} \\mid B) = \\frac{P(B \\mid \\overline{A}) * P(\\overline{A})}{P(B)} = \\frac{P(B \\mid \\overline{A}) * P(\\overline{A})}{P(B \\mid \\overline{A})*P(\\overline{A}) + P(B \\mid A) * P(A)} = \\frac{0.01*0.96}{(0.01*0.96)+(0.97*0.04)} = 0.198\\)\n\\(P(A \\mid B) = 1 - P(\\overline{A} \\mid B) = 1 - 0.192 = 0.802\\)\nOR\n\\(P(A \\mid B) = \\frac{P(B \\mid A) * P(A)}{P(B)} = \\frac{P(B \\mid A) * P(A)}{P(B \\mid A) * P(A) + P(B \\mid \\overline{A})*P(\\overline{A})} = \\frac{0.97*0.04}{(0.97*0.04)+(0.01*0.96)} = 0.802\\)"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#load-library-and-data",
    "href": "content/01_journal/02_statistics.html#load-library-and-data",
    "title": "Statistical Concepts",
    "section": "",
    "text": "library(dplyr)\n\nrandom_vars &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/random_vars.rds\")\n\n\n\n\nageExpectedValue &lt;- summarise(random_vars, mean = mean(age))\nprint(ageExpectedValue)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1  33.5\n\nageVariance &lt;- var(random_vars[,1])\nprint(ageVariance)\n\n#&gt;          age\n#&gt; age 340.6078\n\nageStandardDeviation &lt;- summarise(random_vars, sd = sd(age))\nprint(ageStandardDeviation)\n\n#&gt; # A tibble: 1 × 1\n#&gt;      sd\n#&gt;   &lt;dbl&gt;\n#&gt; 1  18.5\n\n\n\n\n\n\nincomeExpectedValue &lt;- summarise(random_vars, mean = mean(income))\nprint(incomeExpectedValue)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 3511.\n\nincomeVariance &lt;- var(random_vars[,2])\nprint(incomeVariance)\n\n#&gt;         income\n#&gt; income 8625646\n\nincomeStandardDeviation &lt;- summarise(random_vars, sd = sd(income))\nprint(incomeStandardDeviation)\n\n#&gt; # A tibble: 1 × 1\n#&gt;      sd\n#&gt;   &lt;dbl&gt;\n#&gt; 1 2937."
  },
  {
    "objectID": "content/01_journal/02_statistics.html#comparison",
    "href": "content/01_journal/02_statistics.html#comparison",
    "title": "Statistical Concepts",
    "section": "",
    "text": "Well I believe that there’s no sense to compare the standard deviations because simple the income and age aren’t directly related and hence we cannot say that if someone’s age is above the mean with a certain deviation that their income will increase by a certain deviation and vice versa"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#covariance-and-correlation",
    "href": "content/01_journal/02_statistics.html#covariance-and-correlation",
    "title": "Statistical Concepts",
    "section": "",
    "text": "cov &lt;- cov(random_vars[,1],random_vars[,2])\nprint(cov)\n\n#&gt;       income\n#&gt; age 29700.15\n\ncor &lt;- cor(random_vars[,1],random_vars[,2])\nprint(cor)\n\n#&gt;        income\n#&gt; age 0.5479432"
  },
  {
    "objectID": "content/01_journal/02_statistics.html#conditional-expected-value",
    "href": "content/01_journal/02_statistics.html#conditional-expected-value",
    "title": "Statistical Concepts",
    "section": "",
    "text": "\\(E[income \\mid age &gt;= 18]\\)\n\n\ne1 &lt;- summarise(random_vars[random_vars$age&gt;=18,], mean = mean(income))\nprint(e1)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 4464.\n\n\n\n\\(E[income \\mid age \\in [18,65)]\\)\n\n\ne2 &lt;- summarise(random_vars[random_vars$age &gt;= 18 & random_vars$age&lt;65,], mean = mean(income))\nprint(e2)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 4686.\n\n\n\n\\(E[income \\mid age &gt;= 65]\\)\n\n\ne3 &lt;- summarise(random_vars[random_vars$age &gt;= 65,], mean = mean(income))\nprint(e3)\n\n#&gt; # A tibble: 1 × 1\n#&gt;    mean\n#&gt;   &lt;dbl&gt;\n#&gt; 1 1777."
  },
  {
    "objectID": "content/01_journal/02_statistics.html#correlation-vs-covariance",
    "href": "content/01_journal/02_statistics.html#correlation-vs-covariance",
    "title": "Statistical Concepts",
    "section": "",
    "text": "Correlation is easier to interpret because it is bounded with the magnitude showing us how strong or how weak is the relationship and the sign shows us the direction. Meanwhile the covariance is value that doesn’t really tell us much, in terms of the number provided."
  },
  {
    "objectID": "content/01_journal/03_regression.html#import-the-data-set-and-check-dimensions",
    "href": "content/01_journal/03_regression.html#import-the-data-set-and-check-dimensions",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncar_prices &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/car_prices.rds\")\n\ndim(car_prices)\n\n#&gt; [1] 181  22\n\n\nThe dimensions of the data set is 188 rows and 22 coloumns"
  },
  {
    "objectID": "content/01_journal/03_regression.html#data-glimpse-and-lookup",
    "href": "content/01_journal/03_regression.html#data-glimpse-and-lookup",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "glimpse(car_prices)\n\n#&gt; Rows: 181\n#&gt; Columns: 22\n#&gt; $ aspiration       &lt;chr&gt; \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std…\n#&gt; $ doornumber       &lt;chr&gt; \"two\", \"two\", \"two\", \"four\", \"four\", \"two\", \"four\", \"…\n#&gt; $ carbody          &lt;chr&gt; \"convertible\", \"convertible\", \"hatchback\", \"sedan\", \"…\n#&gt; $ drivewheel       &lt;chr&gt; \"rwd\", \"rwd\", \"rwd\", \"fwd\", \"4wd\", \"fwd\", \"fwd\", \"fwd…\n#&gt; $ enginelocation   &lt;chr&gt; \"front\", \"front\", \"front\", \"front\", \"front\", \"front\",…\n#&gt; $ wheelbase        &lt;dbl&gt; 88.6, 88.6, 94.5, 99.8, 99.4, 99.8, 105.8, 105.8, 105…\n#&gt; $ carlength        &lt;dbl&gt; 168.8, 168.8, 171.2, 176.6, 176.6, 177.3, 192.7, 192.…\n#&gt; $ carwidth         &lt;dbl&gt; 64.1, 64.1, 65.5, 66.2, 66.4, 66.3, 71.4, 71.4, 71.4,…\n#&gt; $ carheight        &lt;dbl&gt; 48.8, 48.8, 52.4, 54.3, 54.3, 53.1, 55.7, 55.7, 55.9,…\n#&gt; $ curbweight       &lt;dbl&gt; 2548, 2548, 2823, 2337, 2824, 2507, 2844, 2954, 3086,…\n#&gt; $ enginetype       &lt;chr&gt; \"dohc\", \"dohc\", \"ohcv\", \"ohc\", \"ohc\", \"ohc\", \"ohc\", \"…\n#&gt; $ cylindernumber   &lt;chr&gt; \"four\", \"four\", \"six\", \"four\", \"five\", \"five\", \"five\"…\n#&gt; $ enginesize       &lt;dbl&gt; 130, 130, 152, 109, 136, 136, 136, 136, 131, 131, 108…\n#&gt; $ fuelsystem       &lt;chr&gt; \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi\", \"mpfi…\n#&gt; $ boreratio        &lt;dbl&gt; 3.47, 3.47, 2.68, 3.19, 3.19, 3.19, 3.19, 3.19, 3.13,…\n#&gt; $ stroke           &lt;dbl&gt; 2.68, 2.68, 3.47, 3.40, 3.40, 3.40, 3.40, 3.40, 3.40,…\n#&gt; $ compressionratio &lt;dbl&gt; 9.00, 9.00, 9.00, 10.00, 8.00, 8.50, 8.50, 8.50, 8.30…\n#&gt; $ horsepower       &lt;dbl&gt; 111, 111, 154, 102, 115, 110, 110, 110, 140, 160, 101…\n#&gt; $ peakrpm          &lt;dbl&gt; 5000, 5000, 5000, 5500, 5500, 5500, 5500, 5500, 5500,…\n#&gt; $ citympg          &lt;dbl&gt; 21, 21, 19, 24, 18, 19, 19, 19, 17, 16, 23, 23, 21, 2…\n#&gt; $ highwaympg       &lt;dbl&gt; 27, 27, 26, 30, 22, 25, 25, 25, 20, 22, 29, 29, 28, 2…\n#&gt; $ price            &lt;dbl&gt; 13495.00, 16500.00, 16500.00, 13950.00, 17450.00, 152…\n\n\nHere I used glimpse instead of head to help me see all the coloums and their data types. Strings are recorded as chars and numbers are double allowing decimal values."
  },
  {
    "objectID": "content/01_journal/03_regression.html#linear-regression",
    "href": "content/01_journal/03_regression.html#linear-regression",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "lm_all &lt;- lm(price ~ ., data = car_prices)\nsummary(lm_all)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nFrom the summary we could see that the main factors relevant are:\n\nenginetype (mostly)\neniginesize\nstroke\npeakrpm"
  },
  {
    "objectID": "content/01_journal/03_regression.html#choosing-data-regressor",
    "href": "content/01_journal/03_regression.html#choosing-data-regressor",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "lm_top &lt;- lm(price ~ enginetype +\n                     enginesize +\n                     stroke +\n                     peakrpm,\n                     data = car_prices)\nsummary(lm_top)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ enginetype + enginesize + stroke + peakrpm, \n#&gt;     data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -14872.1  -1453.3   -410.3   1563.4  10058.4 \n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)     -1.618e+04  4.220e+03  -3.834 0.000177 ***\n#&gt; enginetypedohcv  1.280e+03  3.135e+03   0.408 0.683638    \n#&gt; enginetypel      3.842e+03  1.480e+03   2.596 0.010256 *  \n#&gt; enginetypeohc    2.550e+03  9.641e+02   2.645 0.008925 ** \n#&gt; enginetypeohcf   6.534e+02  1.283e+03   0.509 0.611213    \n#&gt; enginetypeohcv  -4.967e+03  1.284e+03  -3.870 0.000154 ***\n#&gt; enginesize       2.145e+02  7.630e+00  28.106  &lt; 2e-16 ***\n#&gt; stroke          -5.398e+03  9.088e+02  -5.939 1.55e-08 ***\n#&gt; peakrpm          3.400e+00  5.522e-01   6.158 5.05e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2971 on 172 degrees of freedom\n#&gt; Multiple R-squared:  0.8704, Adjusted R-squared:  0.8644 \n#&gt; F-statistic: 144.4 on 8 and 172 DF,  p-value: &lt; 2.2e-16\n\n\nAs we can see the smallest p-value is the one for engine size and hence im picking it to be my regressor.\n\nmax(car_prices$enginesize)\n\n#&gt; [1] 326\n\nmin(car_prices$enginesize)\n\n#&gt; [1] 61\n\n\nThe regressor I chose is of type double and its values in this data set ranges from 61 to 326.\nIt has a big effect on the price since the p value is very small it denies the null hypothesis and tells that that there is a strong corellation between both factors.\n\nlm_summarised &lt;- lm(price ~ enginesize, data = car_prices)\nconfint(lm_summarised, level = 0.95)\n\n#&gt;                   2.5 %     97.5 %\n#&gt; (Intercept) -10346.0474 -6898.5441\n#&gt; enginesize     157.1932   182.9353\n\n\nThe estimate is completely positive hence the effect is statistically significant."
  },
  {
    "objectID": "content/01_journal/03_regression.html#adding-the-variable",
    "href": "content/01_journal/03_regression.html#adding-the-variable",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "new_car_prices &lt;- mutate(car_prices, seat_heating = TRUE)\nlm_heat &lt;- lm(price ~ ., data = new_car_prices)\nsummary(lm_heat)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = new_car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/05_dag.html#parking-spots-example",
    "href": "content/01_journal/05_dag.html#parking-spots-example",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "In the parking spots example we had the parking spots as treatment variables, the stores as observation units and the sales as an outcome also taking into consideration the location as a confounder.\n\n# Load packages\nlibrary(dagitty)\nlibrary(ggdag)\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n\n\n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(ggplot2)\n\n#Create DAG model\nparking_model &lt;- dagify(\n  S ~ L,\n  A ~ P,\n  B ~ P,\n  C ~ P,\n  D ~ P,\n  S ~ A,\n  S ~ B,\n  S ~ C,\n  S ~ D,\n  coords = list(x = c(L = 7,P = 1,A = 3,B = 3,C = 3,D = 3,S = 7),\n                y = c(L = 1,P = 0,A = 1,B = 0.5,C = -0.5,D = -1,S = 0)),\n  labels = list(L=\"location\",\n                P = \"parking spots\",\n                A = \"Store A\",\n                B = \"Store B\",\n                C = \"Store C\",\n                D = \"Store D\",\n                S = \"Sales\")\n)\n\n#Plot DAG model\nggdag(parking_model) +\n  theme_dag()+\n  geom_dag_node(color = \"red\")+\n  geom_dag_text(color = \"white\") +\n  geom_dag_edges(edge_color = \"black\") +\n  geom_dag_label_repel(aes(label = label))"
  },
  {
    "objectID": "content/01_journal/05_dag.html#customer-satisfaction",
    "href": "content/01_journal/05_dag.html#customer-satisfaction",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ lubridate 1.9.3     ✔ tibble    3.2.1\n#&gt; ✔ purrr     1.0.2     ✔ tidyr     1.3.0\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks ggdag::filter(), stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncustomer_sat &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/customer_sat.rds\")\nhead(customer_sat)\n\n\n\n  \n\n\nlm_first &lt;- lm(satisfaction ~ follow_ups, data = customer_sat)\nsummary(lm_first)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\nlm_second &lt;- lm(satisfaction ~ follow_ups + subscription, data = customer_sat)\nsummary(lm_second)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n\n\nOne of the possible reasons for having a negative estimate in the first regression and then a positive one in the second could be due to the nature of the follow-up calls. So when we speak about follow-ups in general its usually a problem and at lower subscription levels the solution could be to upgrade their subscription which is more expensive and hence the customer isn’t satisfied with the outcome, it could also be a bug or a complain which applies to all subscription levels but when you factor in the subscription level the nature of the calls could be about an upgrade or an inquiry about a feature that gets resolved and the customer is satisfied.\nAnother explanation that appears later when plotting the data is that when we don’t factor the subscription levels it shows that overall the more the follow-ups the less the satisfaction but when you factor the subscription you find that every subscription level has its own range of satisfaction which when isolated shows us an increase in satisfaction as the increase of follow-ups.\n\n\n\n\nno_sub_sat &lt;- ggplot(customer_sat, aes(x = follow_ups, y = satisfaction)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nsub_sat &lt;- ggplot(customer_sat, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F)\n\nno_sub_sat\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsub_sat\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html#checking-whether-covariates-are-balanced-throughout-the-groups.",
    "href": "content/01_journal/06_rct.html#checking-whether-covariates-are-balanced-throughout-the-groups.",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nabtest &lt;- readRDS(\"~/Documents/TUHH/Casual Data Science for Business Analytics/Causal_Data_Science_Data/abtest_online.rds\")\n\ncompare &lt;- \n  ggplot(abtest, \n         aes(x = chatbot, \n             y = purchase_amount, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = NULL, y = \"Purchase Amount\", title = \"Difference in Purchase Amount\")\n\ncompare\n\n\n\n\n\n\n\n\nAs we can see in the plot the covariates are not balanced."
  },
  {
    "objectID": "content/01_journal/06_rct.html#chatbot-effect-on-sales",
    "href": "content/01_journal/06_rct.html#chatbot-effect-on-sales",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "lm_sales &lt;- lm(purchase_amount ~ chatbot, data = abtest)\nsummary(lm_sales)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = abtest)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n\nThe coefficient is a negative number telling us that the chatbots are affecting the sales in a negative way decreasing the sales and not increasing them."
  },
  {
    "objectID": "content/01_journal/06_rct.html#cate-taking-into-consideration-mobile-users",
    "href": "content/01_journal/06_rct.html#cate-taking-into-consideration-mobile-users",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "lm_sales_plus_mob &lt;- lm(purchase_amount ~ chatbot*mobile_device, data = abtest)\nsummary(lm_sales_plus_mob)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = abtest)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08"
  },
  {
    "objectID": "content/01_journal/06_rct.html#logistic-regression-for-purchase",
    "href": "content/01_journal/06_rct.html#logistic-regression-for-purchase",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "glm_sales &lt;- glm(purchase ~ chatbot, family = binomial(link = 'logit'), abtest)\nsummary(glm_sales)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = abtest)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n\nIn logistic regression we don’t just look at the coefficient but its exponent and that tells us the “odds ratio” which is the ratio of the probability of an event happening divided by the probability of the non event.\nSince the coefficient here is a negative number hence the odds ratio is less than one and that tells us that the event will most likely not happen.\nIn our case the event is the purchase and so the regression tells us that having the chatbot means that the probability of the customer making a purchase is less than that when the customer doesn’t have a chat bot. This means that the chat bot is negatively affecting the number of purchases and hence decreasing the sales."
  }
]